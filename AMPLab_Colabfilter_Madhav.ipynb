{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIApL1RtQ9CR"
      },
      "source": [
        "# AMPLab 2025 Processing large datasets and Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv5l20c8uEi2"
      },
      "source": [
        "Install dependencies in a separate cell, so that if people run it in jupyter with dependencies already present, they can choose to omit it.\n",
        "\n",
        "We also install the `zstd` commandline tool to process our data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-nQKZ1bgEDZ",
        "outputId": "d87ddf9a-9108-45c9-bbd3-6fda87695c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: implicit in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (0.7.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (1.15.2)\n",
            "Requirement already satisfied: h5py in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (3.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (from implicit) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (from implicit) (3.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages (from tqdm>=4.27->implicit) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install implicit numpy scipy h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zyQ_Br9owh7p",
        "outputId": "c9d46353-144c-49b4-ddab-b2faca0e9cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting zstandard\n",
            "  Using cached zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
            "Using cached zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
            "Installing collected packages: zstandard\n",
            "Successfully installed zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install zstandard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVmYiaADn68M",
        "outputId": "a6bf4eca-7d28-4c00-9073-aa107a8837c2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m-LvYZa-TDKT"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import zstandard as zstd\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeS86csquN2P"
      },
      "source": [
        "### Memory management\n",
        "Here's a quick way of seeing what variables are using up a lot of memory.\n",
        "\n",
        "```py\n",
        "import sys\n",
        "global_keys = list(globals().keys())\n",
        "for k in global_keys:\n",
        "  if not k.startswith(\"_\"):\n",
        "    size = sys.getsizeof(globals()[k])\n",
        "    if size > 10000:\n",
        "      print(f\"{k}: {round(size / 1024 / 1024, 2)}MB\")\n",
        "```\n",
        "\n",
        "You can delete any variable by running\n",
        "\n",
        "```py\n",
        "thevariable = None\n",
        "```\n",
        "\n",
        "which will cause python to garbage-collect it and free up the memory. It's worth doing this from time to time in colab if you are at risk of running out of memory in the runtime.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmO7oqwz6kho"
      },
      "source": [
        "# Part 1: Data processing\n",
        "\n",
        "## Step 1: Reading initial data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9cB8FZRdr6qB"
      },
      "outputs": [],
      "source": [
        "# Where the original data files are - use a google drive shortcut so that you don't need to copy them\n",
        "data_root = \"F:/SMC/AMP Lab/Assignment_02/ListenBrainz/2025-materials\"\n",
        "# Local data directory for items that you don't want to lose\n",
        "working_root = \"F:/SMC/AMP Lab/Assignment_02/amplab-working\"\n",
        "# Temporary location that you can use while the colab is running\n",
        "scratch_root = \"F:/SMC/AMP Lab/Assignment_02/amplab-scratch\"\n",
        "os.makedirs(working_root, exist_ok=True)\n",
        "os.makedirs(scratch_root, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXZeELsnuTJQ"
      },
      "source": [
        "Double-check the data directory to see what's there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTJc4yvlRdqL",
        "outputId": "5958f625-28f6-4373-d96f-3b4829adc9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.listens.zst                                      755.02 MB\n",
            "10.listens.zst                                     617.84 MB\n",
            "11.listens.zst                                     618.28 MB\n",
            "12.listens.zst                                     635.66 MB\n",
            "2.listens.zst                                      710.10 MB\n",
            "3.listens.zst                                      737.87 MB\n",
            "4.listens.zst                                      731.43 MB\n",
            "5.listens.zst                                      707.73 MB\n",
            "6.listens.zst                                      626.55 MB\n",
            "7.listens.zst                                      644.80 MB\n",
            "8.listens.zst                                      596.39 MB\n",
            "9.listens.zst                                      589.38 MB\n",
            "canonical_musicbrainz_data.csv.zst                 1478.30 MB\n",
            "canonical_recording_redirect.csv.zst               236.33 MB\n",
            "listenbrainz_model.py                              0.00 MB\n",
            "listenbrainz_msid_mapping.csv-001.zst              3465.63 MB\n",
            "musicbrainz_artist.csv                             122.66 MB\n",
            "musicbrainz_artist_credits.csv                     105.36 MB\n",
            "__pycache__                                        0.00 MB\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "for file in Path(data_root).glob('*'):\n",
        "    print(f\"{file.name:50} {file.stat().st_size/1024/1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kht8Vc9luiDQ"
      },
      "source": [
        "The data files are compressed using the zstandard format. Colab has a \"local disk\" that we can use temporarily. This is not saved when the notebook notebook is closed, but is faster than reading directly from google drive. We can copy a file to our drive and uncompress it to inspect it.\n",
        "\n",
        "We know that a data file is in \"jsonlines\" format, where each line of the file is a json document. We can inspect the first line to see the structure of this document, and see that we want to read the `user_id` and `recording_msid` fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPX9mH8l68ou",
        "outputId": "52224218-e00c-4360-8e8b-c97fb38e1b66"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(scratch_root, \"1.listens\")) as fp:\n",
        "  line = fp.readline()\n",
        "  line_json = json.loads(line)\n",
        "  print(json.dumps(line_json, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_hHyud7ur_5"
      },
      "source": [
        "We can read a file one line at a time, parse the json, and save the user id and recording msid.\n",
        "Note that if you do this for all files then the `data` variable may cause you to run out of memory. Consider this in your work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2bx23yosJov",
        "outputId": "59deb09e-9d11-4bf5-bef1-34585b47122f"
      },
      "outputs": [],
      "source": [
        "def process_listen_files():\n",
        "    all_data = []\n",
        "    # Process all listen files (1-12 for each month)\n",
        "    for file_num in range(1, 13):\n",
        "        input_file = f\"{file_num}.listens.zst\"\n",
        "        compressed_path = Path(data_root) / input_file\n",
        "        decompressed_path = Path(scratch_root) / f\"{file_num}.listens\"\n",
        "        \n",
        "        # Decompress the file\n",
        "        with open(compressed_path, 'rb') as f_in:\n",
        "            with open(decompressed_path, 'wb') as f_out:\n",
        "                dctx = zstd.ZstdDecompressor()\n",
        "                dctx.copy_stream(f_in, f_out)\n",
        "        \n",
        "        # Process the decompressed file\n",
        "        with open(decompressed_path, 'r', encoding='utf-8') as fp:\n",
        "            for line in fp:\n",
        "                try:\n",
        "                    j = json.loads(line)\n",
        "                    user_id = j['user_id']\n",
        "                    recording_msid = j['recording_msid']\n",
        "                    all_data.append([user_id, recording_msid])\n",
        "                except (json.JSONDecodeError, KeyError):\n",
        "                    continue\n",
        "                    \n",
        "        # Clean up decompressed file\n",
        "        decompressed_path.unlink()\n",
        "        \n",
        "        # Show progress\n",
        "        print(f\"Processed file {file_num}/12 - Current total records: {len(all_data):,}\")\n",
        "    \n",
        "    return all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed file 1/12 - Current total records: 8,839,350\n",
            "Processed file 2/12 - Current total records: 17,075,471\n",
            "Processed file 3/12 - Current total records: 25,571,926\n",
            "Processed file 4/12 - Current total records: 33,956,587\n",
            "Processed file 5/12 - Current total records: 42,132,406\n",
            "Processed file 6/12 - Current total records: 49,531,522\n",
            "Processed file 7/12 - Current total records: 57,072,750\n",
            "Processed file 8/12 - Current total records: 64,251,918\n",
            "Processed file 9/12 - Current total records: 71,446,889\n",
            "Processed file 10/12 - Current total records: 78,870,406\n",
            "Processed file 11/12 - Current total records: 86,213,100\n",
            "Processed file 12/12 - Current total records: 93,859,039\n",
            "\n",
            "Total records processed: 93,859,039\n"
          ]
        }
      ],
      "source": [
        "# Process all files\n",
        "data = process_listen_files()\n",
        "print(f\"\\nTotal records processed: {len(data):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zq3ZW0xQsMLp"
      },
      "outputs": [],
      "source": [
        "# Save the data that we extracted to a single file, in case the colab runtime quits\n",
        "# The arguments to `open` are best practices when reading CSV files in python, although I don't always use them\n",
        "# https://docs.python.org/3/library/csv.html#csv.reader\n",
        "with open(os.path.join(working_root, \"userid-msid.csv\"), \"w\", newline='', encoding='utf-8') as fp:\n",
        "    w = csv.writer(fp)\n",
        "    w.writerows(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bScyYjjXsMxw"
      },
      "outputs": [],
      "source": [
        "# Load the data from the previous cell again, if we stopped at this point\n",
        "data = []\n",
        "with open(os.path.join(working_root, \"userid-msid.csv\"), \"r\", newline='', encoding='utf-8') as fp:\n",
        "    r = csv.reader(fp)\n",
        "    for line in r:\n",
        "        data.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEtXTmQLwN3b",
        "outputId": "dbdbff23-d011-4467-ba9e-994abb20dc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of lines in file: 93859039\n"
          ]
        }
      ],
      "source": [
        "# Double-check the total number of lines of data we have\n",
        "line_count = sum(1 for _ in open(os.path.join(working_root, \"userid-msid.csv\"), 'r', encoding='utf-8'))\n",
        "print(f\"Total number of lines in file: {line_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8OVXMEV6z4r"
      },
      "source": [
        "## Step 2: Mapping MSID to MBID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ZoHu4B0Jwh",
        "outputId": "0610ce78-571a-402c-bf2f-2320c53f4471"
      },
      "outputs": [],
      "source": [
        "listenbrainz_msid_mapping_fn = shutil.copy2(os.path.join(data_root, \"listenbrainz_msid_mapping.csv-001.zst\"), scratch_root)\n",
        "compressed_file = Path(scratch_root) / Path(data_root).glob(\"*mapping*.zst\").__next__().name\n",
        "with open(compressed_file, 'rb') as src, open(compressed_file.with_suffix(''), 'wb') as dst:\n",
        "    zstd.ZstdDecompressor().copy_stream(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uell7jULut-8"
      },
      "source": [
        "Try and load the mapping CSV into memory. Ideally I want to have a dictionary such as:\n",
        "\n",
        "```py\n",
        "mapping = {\n",
        "  \"msid1\": \"mbid1\",\n",
        "  \"msid2\": \"mbid\"\n",
        "}\n",
        "```\n",
        "\n",
        "which would allow us to look up an msid in the `data` list above, with just\n",
        "\n",
        "```py\n",
        "mbid = mapping[data[0][1]]\n",
        "```\n",
        "\n",
        "Unfortunately, this CSV file is too large for colab, and it will run out of memory before loading the entire file.\n",
        "\n",
        "However, we can see that the size of the mapping file (111 million rows) is much larger than the number of unique MSIDs that we have in the data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# On colab this cell will run out of memory\n",
        "mapping = {}\n",
        "with open(os.path.join(scratch_root, \"listenbrainz_msid_mapping.csv-001\")) as fp:\n",
        "    r = csv.reader(fp)\n",
        "    # omit header\n",
        "    next(r)\n",
        "    for line in r:\n",
        "        mapping[line[0]] = line[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW2C-M9cxaL-",
        "outputId": "c926cc3c-db38-4839-a748-ba4c7f5cb9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recording_msid,recording_mbid,match_type\n",
            "13ca445f-c0dd-4f64-8726-7da78a3821aa,,no_match\n",
            "54a40ef8-6bfe-4803-b74a-7b93885c2f01,,no_match\n",
            "21c07966-97c6-4e02-a575-e1b2fadf0d34,,no_match\n",
            "3b438b25-b9ad-480f-b248-bd06281919e0,,no_match\n",
            "26d8cc2b-c249-4b70-9f16-4eea1419303c,,no_match\n",
            "bf3fe1e0-7ae6-4e57-a38e-6ac7d42d33c3,,no_match\n",
            "937d9d97-ba8b-4ff4-9af7-1b4a485945c1,,no_match\n",
            "0e9230f2-1d9d-47ab-a44f-dbc788cfbdf1,,no_match\n",
            "2c9111a7-96e6-4083-8b45-78cadb11796e,,no_match\n",
            "012868b2-f6d7-40e6-80a4-d89d077e3d9e,,no_match\n",
            "03feccff-3632-4acf-974b-b787ff7e9bbf,,no_match\n",
            "364902a8-1067-4804-b8be-d6b801ee4179,,no_match\n",
            "13a44caa-8109-46ef-ac25-0e89785bdd18,,no_match\n",
            "273849c3-b1d7-4656-bf67-748c6cac2179,,no_match\n",
            "da3aea98-c857-4eb7-b4d6-cce8aa0318d7,,no_match\n",
            "c514427c-89e1-4746-86bb-49f5d5c8e04a,,no_match\n",
            "67c2a304-1ff5-44ea-a076-9d797ba15c28,,no_match\n",
            "127b9ad4-20d6-49e0-ab82-5aad8d27b5e1,,no_match\n",
            "703adaef-f000-4e6c-bd96-6c9c299af991,,no_match\n",
            "6848ccaf-4942-4fcf-bde3-fbe4e86ede21,,no_match\n",
            "562560cc-a8a0-4857-8e41-35dc8d12ff88,,no_match\n",
            "3a129d6e-99af-460c-ba73-0370015882af,,no_match\n",
            "2912a24b-2895-4591-ac83-ca827fd3f360,,no_match\n",
            "4e50f155-edfb-4fea-b57d-c31bec3abc46,,no_match\n",
            "53228f86-866d-4c46-bf74-aa8cfbcea3e8,d87f867e-9eda-43a6-a45f-faeba1cb441d,exact_match\n",
            "3b6b9eaf-df85-4e85-8d61-406afe8a35a4,c0f27bed-7986-4c88-a9c6-1d16ebc9817b,low_quality\n",
            "891c1359-107e-4a90-98fc-b21b942e300f,543ec930-e1c1-4bb3-aaaf-cb48583fcc49,low_quality\n",
            "bbc5be35-b732-4206-8ae3-ef095060c3d6,65c9cfe2-05f4-45ef-a125-2b38358665f0,exact_match\n",
            "61612055-12bd-4225-8f11-b8036021d72a,66a08ebb-1d9c-4434-bd23-806dda6d2a8d,exact_match\n",
            "5ec25683-f439-42ab-86e9-32b3c9611cdd,e3a5f4f5-2648-4d2a-861f-19524bd558c1,exact_match\n",
            "3f01ed7b-c7b2-42e3-9d28-0e367c4f96db,1dd389b6-cd75-4666-8368-dc01a7d161c9,exact_match\n",
            "e85d90b4-c20c-4d91-aaba-713140de1aad,16fecdbb-4886-46e8-896b-37e78eed633c,exact_match\n",
            "151d14b4-4bfa-438e-904d-0f47c2c109b4,6e6798c0-a7ca-469e-abb3-bc1f87ad6ec4,med_quality\n",
            "5c14b383-4ba4-4fa6-8eaf-ed83d0311b05,961507d0-c2bc-4d69-83c4-f295213bff2b,exact_match\n",
            "ef85039e-4328-408c-afb8-152d37817d00,69291415-fd4e-4c7f-9a81-17a7a60bc60e,exact_match\n",
            "919e9c1e-4353-47fb-b0ba-f344b3fdc760,e241dd9f-0b30-4427-89ea-ba1a8065ee15,exact_match\n",
            "5ff81a61-59c6-4ded-869f-54e161b149a8,75dbbdad-e9fa-46e0-b90f-7085a53bf60e,exact_match\n",
            "5284dd16-cc2b-4981-9527-b7e6e80d98c5,,no_match\n",
            "01c79a31-a6de-4a56-9c95-410a3106af6d,f32d973a-9aef-4d95-ae32-93d75618219b,exact_match\n"
          ]
        }
      ],
      "source": [
        "mapping_file = Path(scratch_root) / \"listenbrainz_msid_mapping.csv-001\"\n",
        "with open(mapping_file, 'r', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 40:\n",
        "            break\n",
        "        print(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO6cemUg4eGo",
        "outputId": "657f8a69-0eff-4956-ea5b-96e683ac4652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of lines in listenbrainz_msid_mapping.csv-001: 111,339,170\n"
          ]
        }
      ],
      "source": [
        "mapping_file = Path(scratch_root) / \"listenbrainz_msid_mapping.csv-001\"\n",
        "with open(mapping_file, 'r', encoding='utf-8') as f:\n",
        "    line_count = sum(1 for _ in f)\n",
        "print(f\"Number of lines in {mapping_file.name}: {line_count:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBExozKX78Ju",
        "outputId": "3cceb94f-7a6d-4a19-9a51-ba9eecf960f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique msids: 16684273\n"
          ]
        }
      ],
      "source": [
        "unique_msids = set(line[1] for line in data)\n",
        "print(f\"Unique msids: {len(unique_msids)}\")\n",
        "# Note that this is even smaller than the 8.8m lines in the file `userid-msid.csv`, because we're removing duplicates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TILt7ZrG78ZH"
      },
      "source": [
        "Therefore, we can read the mapping file one line at a time and make a new small mapping file containing only the MSID values that we need.\n",
        "\n",
        "**Trick:** This is one of the tricks to work with large amounts of data without loading it into memory. You can read the file one line at a time (python does this if you iterate over a csv reader such as `for line in r`), or you could use `fp.readline`. You could also do a variant of this by reading a data frame in pandas in chunks (e.g. 100,000 lines at a time), and processing each chunk before moving on to the next one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf8dJeo5_CJd"
      },
      "source": [
        "I decided to read all lines in the mapping, but you could also decide to use only exact match or high quality results.\n",
        "If you look at the mapping file you can see that the 3rd column contains a \"match_type\" field representing the quality of the match. This can be \"exact_match\", \"high_quality\", \"med_quality\", \"low_quality\", or \"no_match\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmx_i0NwbCb",
        "outputId": "3b2ef127-8bb2-4d31-c5fa-42f75b925676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique match types:\n",
            "- exact_match\n",
            "- high_quality\n",
            "- low_quality\n",
            "- med_quality\n",
            "- no_match\n"
          ]
        }
      ],
      "source": [
        "mapping_file = Path(scratch_root) / \"listenbrainz_msid_mapping.csv-001\"\n",
        "\n",
        "with open(mapping_file, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # Skip header\n",
        "    match_types = {row[2] for _, row in zip(range(1000), reader) if len(row) > 2}\n",
        "\n",
        "print(\"Unique match types:\")\n",
        "print('\\n'.join(f\"- {t}\" for t in sorted(match_types)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "njf_bM8oB1G2"
      },
      "outputs": [],
      "source": [
        "# Here we don't even need to store the entire contents of these files.\n",
        "# Instead we just read the first file 1 line and a time and write a new line directly to the 2nd file if needed.\n",
        "with open(os.path.join(scratch_root, \"listenbrainz_msid_mapping.csv-001\")) as r_fp, open(os.path.join(scratch_root, \"small_msid_mapping.csv-001\"), \"w\") as w_fp:\n",
        "    r = csv.reader(r_fp)\n",
        "    w = csv.writer(w_fp)\n",
        "    header = next(r)\n",
        "    w.writerow(header)\n",
        "    for line in r:\n",
        "      if line[0] in unique_msids and line[2] != \"no_match\":\n",
        "        w.writerow(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAsvCEN6sRrB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 100,000 matches\n",
            "Processed 200,000 matches\n",
            "Processed 300,000 matches\n",
            "Processed 400,000 matches\n",
            "Processed 500,000 matches\n",
            "Processed 600,000 matches\n",
            "Processed 700,000 matches\n",
            "Processed 800,000 matches\n",
            "Processed 900,000 matches\n",
            "Processed 1,000,000 matches\n",
            "Processed 1,100,000 matches\n",
            "Processed 1,200,000 matches\n",
            "Processed 1,300,000 matches\n",
            "Processed 1,400,000 matches\n",
            "Processed 1,500,000 matches\n",
            "Processed 1,600,000 matches\n",
            "Processed 1,700,000 matches\n",
            "Processed 1,800,000 matches\n",
            "Processed 1,900,000 matches\n",
            "Processed 2,000,000 matches\n",
            "Processed 2,100,000 matches\n",
            "Processed 2,200,000 matches\n",
            "Processed 2,300,000 matches\n",
            "Processed 2,400,000 matches\n",
            "Processed 2,500,000 matches\n",
            "Processed 2,600,000 matches\n",
            "Processed 2,700,000 matches\n",
            "Processed 2,800,000 matches\n",
            "Processed 2,900,000 matches\n",
            "Processed 3,000,000 matches\n",
            "Processed 3,100,000 matches\n",
            "Processed 3,200,000 matches\n",
            "Processed 3,300,000 matches\n",
            "Processed 3,400,000 matches\n",
            "Processed 3,500,000 matches\n",
            "Processed 3,600,000 matches\n",
            "Processed 3,700,000 matches\n",
            "Processed 3,800,000 matches\n",
            "Processed 3,900,000 matches\n",
            "Processed 4,000,000 matches\n",
            "Processed 4,100,000 matches\n",
            "Processed 4,200,000 matches\n",
            "Processed 4,300,000 matches\n",
            "Processed 4,400,000 matches\n",
            "Processed 4,500,000 matches\n",
            "Processed 4,600,000 matches\n",
            "Processed 4,700,000 matches\n",
            "Processed 4,800,000 matches\n",
            "Processed 4,900,000 matches\n",
            "Processed 5,000,000 matches\n",
            "Processed 5,100,000 matches\n",
            "Processed 5,200,000 matches\n",
            "Processed 5,300,000 matches\n",
            "Processed 5,400,000 matches\n",
            "Processed 5,500,000 matches\n",
            "Processed 5,600,000 matches\n",
            "Processed 5,700,000 matches\n",
            "Processed 5,800,000 matches\n",
            "Processed 5,900,000 matches\n",
            "Processed 6,000,000 matches\n",
            "Processed 6,100,000 matches\n",
            "Processed 6,200,000 matches\n",
            "Processed 6,300,000 matches\n",
            "Processed 6,400,000 matches\n",
            "Processed 6,500,000 matches\n",
            "Processed 6,600,000 matches\n",
            "Processed 6,700,000 matches\n",
            "Processed 6,800,000 matches\n",
            "Processed 6,900,000 matches\n",
            "Processed 7,000,000 matches\n",
            "Processed 7,100,000 matches\n",
            "Processed 7,200,000 matches\n",
            "Processed 7,300,000 matches\n",
            "Processed 7,400,000 matches\n",
            "Processed 7,500,000 matches\n",
            "Processed 7,600,000 matches\n",
            "Processed 7,700,000 matches\n",
            "Processed 7,800,000 matches\n",
            "Processed 7,900,000 matches\n",
            "Processed 8,000,000 matches\n",
            "Processed 8,100,000 matches\n",
            "Processed 8,200,000 matches\n",
            "Processed 8,300,000 matches\n",
            "Processed 8,400,000 matches\n",
            "Processed 8,500,000 matches\n",
            "Processed 8,600,000 matches\n",
            "Processed 8,700,000 matches\n",
            "Processed 8,800,000 matches\n",
            "Processed 8,900,000 matches\n",
            "Processed 9,000,000 matches\n",
            "Processed 9,100,000 matches\n",
            "\n",
            "Stats:\n",
            "Total unique MSIDs: 16,684,273\n",
            "High-quality matches found: 9,175,609\n",
            "Coverage: 55.00%\n"
          ]
        }
      ],
      "source": [
        "# Define input and output files\n",
        "input_file = Path(scratch_root) / \"listenbrainz_msid_mapping.csv-001\"\n",
        "output_file = Path(scratch_root) / \"high_quality_mapping.csv\"\n",
        "\n",
        "# Process the mapping file, filtering for high-quality matches\n",
        "matched = 0\n",
        "with open(input_file, 'r', encoding='utf-8') as r_fp, \\\n",
        "     open(output_file, 'w', newline='', encoding='utf-8') as w_fp:\n",
        "    reader = csv.reader(r_fp)\n",
        "    writer = csv.writer(w_fp)\n",
        "    \n",
        "    # Copy header\n",
        "    writer.writerow(next(reader))\n",
        "    \n",
        "    # Filter and write only high-quality and exact matches for our MSIDs\n",
        "    for line in reader:\n",
        "        if (line[0] in unique_msids and \n",
        "            line[2] in (\"exact_match\", \"high_quality\")):\n",
        "            writer.writerow(line)\n",
        "            matched += 1\n",
        "            if matched % 100000 == 0:  # Simple progress indicator\n",
        "                print(f\"Processed {matched:,} matches\")\n",
        "\n",
        "print(f\"\\nStats:\")\n",
        "print(f\"Total unique MSIDs: {len(unique_msids):,}\")\n",
        "print(f\"High-quality matches found: {matched:,}\")\n",
        "print(f\"Coverage: {matched/len(unique_msids)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ4hqCri_WvC"
      },
      "source": [
        "Now that we have a small mapping file, we know that it will fit in memory. Until now, `data` has been in memory (a list of userid/msid pairs).\n",
        "\n",
        "We can free up the `data` variable from memory, load the mapping, and then process the \"userid-msid.csv\" file, one line at a time, immediately writing out a new file with the relevant MBID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3jc7JXRa5-s0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 11,351,391 mappings\n",
            "\n",
            "First few mappings:\n",
            "MSID: 61612055-12bd-4225-8f11-b8036021d72a -> MBID: 66a08ebb-1d9c-4434-bd23-806dda6d2a8d\n",
            "MSID: 5ec25683-f439-42ab-86e9-32b3c9611cdd -> MBID: e3a5f4f5-2648-4d2a-861f-19524bd558c1\n",
            "MSID: 01c79a31-a6de-4a56-9c95-410a3106af6d -> MBID: f32d973a-9aef-4d95-ae32-93d75618219b\n",
            "MSID: 881427b4-cfa5-4223-8fa3-288aa944525c -> MBID: 43a21737-0462-423d-9105-c5f63d67b5b0\n",
            "MSID: 6b245bfc-0064-473d-8305-bb51467c4d12 -> MBID: 39db4cae-d9d1-4807-8be6-49e72bccb3da\n"
          ]
        }
      ],
      "source": [
        "# Process the filtered mapping file\n",
        "smallmapping = {}\n",
        "with open(Path(scratch_root) / \"small_msid_mapping.csv-001\", 'r', encoding='utf-8') as fp:\n",
        "    reader = csv.reader(fp)\n",
        "    next(reader)  # Skip header\n",
        "    for line in reader:\n",
        "        # Only process lines that have at least 2 columns\n",
        "        if len(line) >= 2:\n",
        "            smallmapping[line[0]] = line[1]\n",
        "\n",
        "print(f\"Loaded {len(smallmapping):,} mappings\")\n",
        "\n",
        "# Verify a few entries\n",
        "print(\"\\nFirst few mappings:\")\n",
        "for i, (msid, mbid) in enumerate(list(smallmapping.items())[:5]):\n",
        "    print(f\"MSID: {msid} -> MBID: {mbid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Canonical Redirect Processing\n",
        "Process canonical redirects for MBIDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# decompress the canonical redirect file\n",
        "canonical_redirect_zst = Path(data_root) / \"canonical_recording_redirect.csv.zst\"\n",
        "canonical_redirect_csv = Path(scratch_root) / \"canonical_recording_redirect.csv\"\n",
        "\n",
        "if not canonical_redirect_csv.exists():\n",
        "    with open(canonical_redirect_zst, 'rb') as src, open(canonical_redirect_csv, 'wb') as dst:\n",
        "        zstd.ZstdDecompressor().copy_stream(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final mapping file\n",
        "final_mapping_file = Path(scratch_root) / \"final_canonical_mapping.csv\"\n",
        "\n",
        "def process_canonical_redirects():\n",
        "    redirects_processed = 0\n",
        "    mappings_processed = 0\n",
        "    \n",
        "    # Open output file for writing canonical mappings\n",
        "    with open(final_mapping_file, 'w', newline='', encoding='utf-8') as out_fp:\n",
        "        writer = csv.writer(out_fp)\n",
        "        writer.writerow(['msid', 'canonical_mbid'])  # Write header\n",
        "        \n",
        "        # Process redirects in chunks\n",
        "        chunk_size = 100000\n",
        "        current_chunk = {}\n",
        "        \n",
        "        # Read canonical redirects and process in chunks\n",
        "        with open(canonical_redirect_csv, 'r', encoding='utf-8') as redirect_fp:\n",
        "            redirect_reader = csv.reader(redirect_fp)\n",
        "            next(redirect_reader)  # Skip header\n",
        "            \n",
        "            # Process smallmapping entries\n",
        "            for msid, mbid in smallmapping.items():\n",
        "                # Read next chunk of redirects\n",
        "                if len(current_chunk) == 0:\n",
        "                    current_chunk = {}\n",
        "                    for _ in range(chunk_size):\n",
        "                        try:\n",
        "                            line = next(redirect_reader)\n",
        "                            if len(line) >= 2:\n",
        "                                current_chunk[line[0]] = line[1]\n",
        "                                redirects_processed += 1\n",
        "                        except StopIteration:\n",
        "                            break\n",
        "                \n",
        "                # Look up in current chunk or use original\n",
        "                canonical_mbid = current_chunk.get(mbid, mbid)\n",
        "                writer.writerow([msid, canonical_mbid])\n",
        "                mappings_processed += 1\n",
        "                \n",
        "                if mappings_processed % 100000 == 0:\n",
        "                    print(f\"Processed {mappings_processed:,} mappings\")\n",
        "\n",
        "    return redirects_processed, mappings_processed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 100,000 mappings\n",
            "Processed 200,000 mappings\n",
            "Processed 300,000 mappings\n",
            "Processed 400,000 mappings\n",
            "Processed 500,000 mappings\n",
            "Processed 600,000 mappings\n",
            "Processed 700,000 mappings\n",
            "Processed 800,000 mappings\n",
            "Processed 900,000 mappings\n",
            "Processed 1,000,000 mappings\n",
            "Processed 1,100,000 mappings\n",
            "Processed 1,200,000 mappings\n",
            "Processed 1,300,000 mappings\n",
            "Processed 1,400,000 mappings\n",
            "Processed 1,500,000 mappings\n",
            "Processed 1,600,000 mappings\n",
            "Processed 1,700,000 mappings\n",
            "Processed 1,800,000 mappings\n",
            "Processed 1,900,000 mappings\n",
            "Processed 2,000,000 mappings\n",
            "Processed 2,100,000 mappings\n",
            "Processed 2,200,000 mappings\n",
            "Processed 2,300,000 mappings\n",
            "Processed 2,400,000 mappings\n",
            "Processed 2,500,000 mappings\n",
            "Processed 2,600,000 mappings\n",
            "Processed 2,700,000 mappings\n",
            "Processed 2,800,000 mappings\n",
            "Processed 2,900,000 mappings\n",
            "Processed 3,000,000 mappings\n",
            "Processed 3,100,000 mappings\n",
            "Processed 3,200,000 mappings\n",
            "Processed 3,300,000 mappings\n",
            "Processed 3,400,000 mappings\n",
            "Processed 3,500,000 mappings\n",
            "Processed 3,600,000 mappings\n",
            "Processed 3,700,000 mappings\n",
            "Processed 3,800,000 mappings\n",
            "Processed 3,900,000 mappings\n",
            "Processed 4,000,000 mappings\n",
            "Processed 4,100,000 mappings\n",
            "Processed 4,200,000 mappings\n",
            "Processed 4,300,000 mappings\n",
            "Processed 4,400,000 mappings\n",
            "Processed 4,500,000 mappings\n",
            "Processed 4,600,000 mappings\n",
            "Processed 4,700,000 mappings\n",
            "Processed 4,800,000 mappings\n",
            "Processed 4,900,000 mappings\n",
            "Processed 5,000,000 mappings\n",
            "Processed 5,100,000 mappings\n",
            "Processed 5,200,000 mappings\n",
            "Processed 5,300,000 mappings\n",
            "Processed 5,400,000 mappings\n",
            "Processed 5,500,000 mappings\n",
            "Processed 5,600,000 mappings\n",
            "Processed 5,700,000 mappings\n",
            "Processed 5,800,000 mappings\n",
            "Processed 5,900,000 mappings\n",
            "Processed 6,000,000 mappings\n",
            "Processed 6,100,000 mappings\n",
            "Processed 6,200,000 mappings\n",
            "Processed 6,300,000 mappings\n",
            "Processed 6,400,000 mappings\n",
            "Processed 6,500,000 mappings\n",
            "Processed 6,600,000 mappings\n",
            "Processed 6,700,000 mappings\n",
            "Processed 6,800,000 mappings\n",
            "Processed 6,900,000 mappings\n",
            "Processed 7,000,000 mappings\n",
            "Processed 7,100,000 mappings\n",
            "Processed 7,200,000 mappings\n",
            "Processed 7,300,000 mappings\n",
            "Processed 7,400,000 mappings\n",
            "Processed 7,500,000 mappings\n",
            "Processed 7,600,000 mappings\n",
            "Processed 7,700,000 mappings\n",
            "Processed 7,800,000 mappings\n",
            "Processed 7,900,000 mappings\n",
            "Processed 8,000,000 mappings\n",
            "Processed 8,100,000 mappings\n",
            "Processed 8,200,000 mappings\n",
            "Processed 8,300,000 mappings\n",
            "Processed 8,400,000 mappings\n",
            "Processed 8,500,000 mappings\n",
            "Processed 8,600,000 mappings\n",
            "Processed 8,700,000 mappings\n",
            "Processed 8,800,000 mappings\n",
            "Processed 8,900,000 mappings\n",
            "Processed 9,000,000 mappings\n",
            "Processed 9,100,000 mappings\n",
            "Processed 9,200,000 mappings\n",
            "Processed 9,300,000 mappings\n",
            "Processed 9,400,000 mappings\n",
            "Processed 9,500,000 mappings\n",
            "Processed 9,600,000 mappings\n",
            "Processed 9,700,000 mappings\n",
            "Processed 9,800,000 mappings\n",
            "Processed 9,900,000 mappings\n",
            "Processed 10,000,000 mappings\n",
            "Processed 10,100,000 mappings\n",
            "Processed 10,200,000 mappings\n",
            "Processed 10,300,000 mappings\n",
            "Processed 10,400,000 mappings\n",
            "Processed 10,500,000 mappings\n",
            "Processed 10,600,000 mappings\n",
            "Processed 10,700,000 mappings\n",
            "Processed 10,800,000 mappings\n",
            "Processed 10,900,000 mappings\n",
            "Processed 11,000,000 mappings\n",
            "Processed 11,100,000 mappings\n",
            "Processed 11,200,000 mappings\n",
            "Processed 11,300,000 mappings\n",
            "\n",
            "Stats:\n",
            "Redirects processed: 100,000\n",
            "Final mappings created: 11,351,391\n",
            "\n",
            "First few lines of final mapping:\n",
            "msid,canonical_mbid\n",
            "61612055-12bd-4225-8f11-b8036021d72a,66a08ebb-1d9c-4434-bd23-806dda6d2a8d\n",
            "5ec25683-f439-42ab-86e9-32b3c9611cdd,e3a5f4f5-2648-4d2a-861f-19524bd558c1\n",
            "01c79a31-a6de-4a56-9c95-410a3106af6d,f32d973a-9aef-4d95-ae32-93d75618219b\n",
            "881427b4-cfa5-4223-8fa3-288aa944525c,43a21737-0462-423d-9105-c5f63d67b5b0\n"
          ]
        }
      ],
      "source": [
        "# Process the mappings\n",
        "redirects_count, final_count = process_canonical_redirects()\n",
        "\n",
        "print(f\"\\nStats:\")\n",
        "print(f\"Redirects processed: {redirects_count:,}\")\n",
        "print(f\"Final mappings created: {final_count:,}\")\n",
        "\n",
        "# Verify the output file\n",
        "print(f\"\\nFirst few lines of final mapping:\")\n",
        "with open(final_mapping_file, 'r', encoding='utf-8') as f:\n",
        "    for _ in range(5):\n",
        "        print(f.readline().strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decompressing canonical musicbrainz data...\n"
          ]
        }
      ],
      "source": [
        "# Decompress canonical musicbrainz data\n",
        "canonical_data_zst = Path(data_root) / \"canonical_musicbrainz_data.csv.zst\"\n",
        "canonical_data_csv = Path(scratch_root) / \"canonical_musicbrainz_data.csv\"\n",
        "\n",
        "if not canonical_data_csv.exists():\n",
        "    print(\"Decompressing canonical musicbrainz data...\")\n",
        "    with open(canonical_data_zst, 'rb') as src, open(canonical_data_csv, 'wb') as dst:\n",
        "        zstd.ZstdDecompressor().copy_stream(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File structure:\n",
            "Header: ['id', 'artist_credit_id', 'artist_mbids', 'artist_credit_name', 'release_mbid', 'release_name', 'recording_mbid', 'recording_name', 'combined_lookup', 'score']\n",
            "\n",
            "First row example:\n",
            "['1', '1', '89ad4ac3-39f7-470e-963a-56509c546377', 'Various Artists', '4fd4f7ee-cee8-47fd-84d2-8d65e74bd8f7', 'Nadal en galego', '00b1a29d-ad9e-4b64-aed6-281f69f628ae', 'Catro Mancebos', 'variousartistscatromancebos', '91870']\n"
          ]
        }
      ],
      "source": [
        "# Look at the first few lines\n",
        "with open(canonical_data_csv, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    print(\"File structure:\")\n",
        "    print(f\"Header: {header}\")\n",
        "    print(\"\\nFirst row example:\")\n",
        "    print(next(reader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Artist information processing\n",
        "\n",
        "- In this step I chose to take the first artist when multiple artists exist\n",
        "- Create \"recording_artist_mapping.csv\" containing:\n",
        "    - Recording MBID\n",
        "    - Artist MBID\n",
        "    - Artist name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_recording_to_artist_mapping():\n",
        "    \"\"\"Process canonical data to map recordings to their first artists\"\"\"\n",
        "    \n",
        "    output_file = Path(scratch_root) / \"recording_artist_mapping.csv\"\n",
        "    processed = 0\n",
        "    \n",
        "    with open(canonical_data_csv, 'r', encoding='utf-8') as f_in, \\\n",
        "         open(output_file, 'w', newline='', encoding='utf-8') as f_out:\n",
        "        reader = csv.reader(f_in)\n",
        "        writer = csv.writer(f_out)\n",
        "        \n",
        "        # Write header\n",
        "        header = next(reader)\n",
        "        writer.writerow(['recording_mbid', 'artist_mbid', 'artist_name'])\n",
        "        \n",
        "        for row in reader:\n",
        "            if len(row) < 8:  # Ensure we have all needed fields\n",
        "                continue\n",
        "                \n",
        "            recording_mbid = row[6]\n",
        "            artist_mbids = row[2].split(';') if row[2] else []\n",
        "            artist_name = row[3]\n",
        "            \n",
        "            # Take only the first artist\n",
        "            if artist_mbids:\n",
        "                writer.writerow([recording_mbid, artist_mbids[0], artist_name])\n",
        "            \n",
        "            processed += 1\n",
        "            if processed % 100000 == 0:\n",
        "                print(f\"Processed {processed:,} recordings\")\n",
        "    \n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 100,000 recordings\n",
            "Processed 200,000 recordings\n",
            "Processed 300,000 recordings\n",
            "Processed 400,000 recordings\n",
            "Processed 500,000 recordings\n",
            "Processed 600,000 recordings\n",
            "Processed 700,000 recordings\n",
            "Processed 800,000 recordings\n",
            "Processed 900,000 recordings\n",
            "Processed 1,000,000 recordings\n",
            "Processed 1,100,000 recordings\n",
            "Processed 1,200,000 recordings\n",
            "Processed 1,300,000 recordings\n",
            "Processed 1,400,000 recordings\n",
            "Processed 1,500,000 recordings\n",
            "Processed 1,600,000 recordings\n",
            "Processed 1,700,000 recordings\n",
            "Processed 1,800,000 recordings\n",
            "Processed 1,900,000 recordings\n",
            "Processed 2,000,000 recordings\n",
            "Processed 2,100,000 recordings\n",
            "Processed 2,200,000 recordings\n",
            "Processed 2,300,000 recordings\n",
            "Processed 2,400,000 recordings\n",
            "Processed 2,500,000 recordings\n",
            "Processed 2,600,000 recordings\n",
            "Processed 2,700,000 recordings\n",
            "Processed 2,800,000 recordings\n",
            "Processed 2,900,000 recordings\n",
            "Processed 3,000,000 recordings\n",
            "Processed 3,100,000 recordings\n",
            "Processed 3,200,000 recordings\n",
            "Processed 3,300,000 recordings\n",
            "Processed 3,400,000 recordings\n",
            "Processed 3,500,000 recordings\n",
            "Processed 3,600,000 recordings\n",
            "Processed 3,700,000 recordings\n",
            "Processed 3,800,000 recordings\n",
            "Processed 3,900,000 recordings\n",
            "Processed 4,000,000 recordings\n",
            "Processed 4,100,000 recordings\n",
            "Processed 4,200,000 recordings\n",
            "Processed 4,300,000 recordings\n",
            "Processed 4,400,000 recordings\n",
            "Processed 4,500,000 recordings\n",
            "Processed 4,600,000 recordings\n",
            "Processed 4,700,000 recordings\n",
            "Processed 4,800,000 recordings\n",
            "Processed 4,900,000 recordings\n",
            "Processed 5,000,000 recordings\n",
            "Processed 5,100,000 recordings\n",
            "Processed 5,200,000 recordings\n",
            "Processed 5,300,000 recordings\n",
            "Processed 5,400,000 recordings\n",
            "Processed 5,500,000 recordings\n",
            "Processed 5,600,000 recordings\n",
            "Processed 5,700,000 recordings\n",
            "Processed 5,800,000 recordings\n",
            "Processed 5,900,000 recordings\n",
            "Processed 6,000,000 recordings\n",
            "Processed 6,100,000 recordings\n",
            "Processed 6,200,000 recordings\n",
            "Processed 6,300,000 recordings\n",
            "Processed 6,400,000 recordings\n",
            "Processed 6,500,000 recordings\n",
            "Processed 6,600,000 recordings\n",
            "Processed 6,700,000 recordings\n",
            "Processed 6,800,000 recordings\n",
            "Processed 6,900,000 recordings\n",
            "Processed 7,000,000 recordings\n",
            "Processed 7,100,000 recordings\n",
            "Processed 7,200,000 recordings\n",
            "Processed 7,300,000 recordings\n",
            "Processed 7,400,000 recordings\n",
            "Processed 7,500,000 recordings\n",
            "Processed 7,600,000 recordings\n",
            "Processed 7,700,000 recordings\n",
            "Processed 7,800,000 recordings\n",
            "Processed 7,900,000 recordings\n",
            "Processed 8,000,000 recordings\n",
            "Processed 8,100,000 recordings\n",
            "Processed 8,200,000 recordings\n",
            "Processed 8,300,000 recordings\n",
            "Processed 8,400,000 recordings\n",
            "Processed 8,500,000 recordings\n",
            "Processed 8,600,000 recordings\n",
            "Processed 8,700,000 recordings\n",
            "Processed 8,800,000 recordings\n",
            "Processed 8,900,000 recordings\n",
            "Processed 9,000,000 recordings\n",
            "Processed 9,100,000 recordings\n",
            "Processed 9,200,000 recordings\n",
            "Processed 9,300,000 recordings\n",
            "Processed 9,400,000 recordings\n",
            "Processed 9,500,000 recordings\n",
            "Processed 9,600,000 recordings\n",
            "Processed 9,700,000 recordings\n",
            "Processed 9,800,000 recordings\n",
            "Processed 9,900,000 recordings\n",
            "Processed 10,000,000 recordings\n",
            "Processed 10,100,000 recordings\n",
            "Processed 10,200,000 recordings\n",
            "Processed 10,300,000 recordings\n",
            "Processed 10,400,000 recordings\n",
            "Processed 10,500,000 recordings\n",
            "Processed 10,600,000 recordings\n",
            "Processed 10,700,000 recordings\n",
            "Processed 10,800,000 recordings\n",
            "Processed 10,900,000 recordings\n",
            "Processed 11,000,000 recordings\n",
            "Processed 11,100,000 recordings\n",
            "Processed 11,200,000 recordings\n",
            "Processed 11,300,000 recordings\n",
            "Processed 11,400,000 recordings\n",
            "Processed 11,500,000 recordings\n",
            "Processed 11,600,000 recordings\n",
            "Processed 11,700,000 recordings\n",
            "Processed 11,800,000 recordings\n",
            "Processed 11,900,000 recordings\n",
            "Processed 12,000,000 recordings\n",
            "Processed 12,100,000 recordings\n",
            "Processed 12,200,000 recordings\n",
            "Processed 12,300,000 recordings\n",
            "Processed 12,400,000 recordings\n",
            "Processed 12,500,000 recordings\n",
            "Processed 12,600,000 recordings\n",
            "Processed 12,700,000 recordings\n",
            "Processed 12,800,000 recordings\n",
            "Processed 12,900,000 recordings\n",
            "Processed 13,000,000 recordings\n",
            "Processed 13,100,000 recordings\n",
            "Processed 13,200,000 recordings\n",
            "Processed 13,300,000 recordings\n",
            "Processed 13,400,000 recordings\n",
            "Processed 13,500,000 recordings\n",
            "Processed 13,600,000 recordings\n",
            "Processed 13,700,000 recordings\n",
            "Processed 13,800,000 recordings\n",
            "Processed 13,900,000 recordings\n",
            "Processed 14,000,000 recordings\n",
            "Processed 14,100,000 recordings\n",
            "Processed 14,200,000 recordings\n",
            "Processed 14,300,000 recordings\n",
            "Processed 14,400,000 recordings\n",
            "Processed 14,500,000 recordings\n",
            "Processed 14,600,000 recordings\n",
            "Processed 14,700,000 recordings\n",
            "Processed 14,800,000 recordings\n",
            "Processed 14,900,000 recordings\n",
            "Processed 15,000,000 recordings\n",
            "Processed 15,100,000 recordings\n",
            "Processed 15,200,000 recordings\n",
            "Processed 15,300,000 recordings\n",
            "Processed 15,400,000 recordings\n",
            "Processed 15,500,000 recordings\n",
            "Processed 15,600,000 recordings\n",
            "Processed 15,700,000 recordings\n",
            "Processed 15,800,000 recordings\n",
            "Processed 15,900,000 recordings\n",
            "Processed 16,000,000 recordings\n",
            "Processed 16,100,000 recordings\n",
            "Processed 16,200,000 recordings\n",
            "Processed 16,300,000 recordings\n",
            "Processed 16,400,000 recordings\n",
            "Processed 16,500,000 recordings\n",
            "Processed 16,600,000 recordings\n",
            "Processed 16,700,000 recordings\n",
            "Processed 16,800,000 recordings\n",
            "Processed 16,900,000 recordings\n",
            "Processed 17,000,000 recordings\n",
            "Processed 17,100,000 recordings\n",
            "Processed 17,200,000 recordings\n",
            "Processed 17,300,000 recordings\n",
            "Processed 17,400,000 recordings\n",
            "Processed 17,500,000 recordings\n",
            "Processed 17,600,000 recordings\n",
            "Processed 17,700,000 recordings\n",
            "Processed 17,800,000 recordings\n",
            "Processed 17,900,000 recordings\n",
            "Processed 18,000,000 recordings\n",
            "Processed 18,100,000 recordings\n",
            "Processed 18,200,000 recordings\n",
            "Processed 18,300,000 recordings\n",
            "Processed 18,400,000 recordings\n",
            "Processed 18,500,000 recordings\n",
            "Processed 18,600,000 recordings\n",
            "Processed 18,700,000 recordings\n",
            "Processed 18,800,000 recordings\n",
            "Processed 18,900,000 recordings\n",
            "Processed 19,000,000 recordings\n",
            "Processed 19,100,000 recordings\n",
            "Processed 19,200,000 recordings\n",
            "Processed 19,300,000 recordings\n",
            "Processed 19,400,000 recordings\n",
            "Processed 19,500,000 recordings\n",
            "Processed 19,600,000 recordings\n",
            "Processed 19,700,000 recordings\n",
            "Processed 19,800,000 recordings\n",
            "Processed 19,900,000 recordings\n",
            "Processed 20,000,000 recordings\n",
            "Processed 20,100,000 recordings\n",
            "Processed 20,200,000 recordings\n",
            "Processed 20,300,000 recordings\n",
            "Processed 20,400,000 recordings\n",
            "Processed 20,500,000 recordings\n",
            "Processed 20,600,000 recordings\n",
            "Processed 20,700,000 recordings\n",
            "Processed 20,800,000 recordings\n",
            "Processed 20,900,000 recordings\n",
            "Processed 21,000,000 recordings\n",
            "Processed 21,100,000 recordings\n",
            "Processed 21,200,000 recordings\n",
            "Processed 21,300,000 recordings\n",
            "Processed 21,400,000 recordings\n",
            "Processed 21,500,000 recordings\n",
            "Processed 21,600,000 recordings\n",
            "Processed 21,700,000 recordings\n",
            "Processed 21,800,000 recordings\n",
            "Processed 21,900,000 recordings\n",
            "Processed 22,000,000 recordings\n",
            "Processed 22,100,000 recordings\n",
            "Processed 22,200,000 recordings\n",
            "Processed 22,300,000 recordings\n",
            "Processed 22,400,000 recordings\n",
            "Processed 22,500,000 recordings\n",
            "Processed 22,600,000 recordings\n",
            "Processed 22,700,000 recordings\n",
            "Processed 22,800,000 recordings\n",
            "Processed 22,900,000 recordings\n",
            "Processed 23,000,000 recordings\n",
            "Processed 23,100,000 recordings\n",
            "Processed 23,200,000 recordings\n",
            "Processed 23,300,000 recordings\n",
            "Processed 23,400,000 recordings\n",
            "Processed 23,500,000 recordings\n",
            "Processed 23,600,000 recordings\n",
            "Processed 23,700,000 recordings\n",
            "Processed 23,800,000 recordings\n",
            "Processed 23,900,000 recordings\n",
            "Processed 24,000,000 recordings\n",
            "Processed 24,100,000 recordings\n",
            "Processed 24,200,000 recordings\n",
            "Processed 24,300,000 recordings\n",
            "Processed 24,400,000 recordings\n",
            "Processed 24,500,000 recordings\n",
            "Processed 24,600,000 recordings\n",
            "Processed 24,700,000 recordings\n",
            "Processed 24,800,000 recordings\n",
            "Processed 24,900,000 recordings\n",
            "Processed 25,000,000 recordings\n",
            "Processed 25,100,000 recordings\n",
            "Processed 25,200,000 recordings\n",
            "Processed 25,300,000 recordings\n",
            "Processed 25,400,000 recordings\n",
            "Processed 25,500,000 recordings\n",
            "Processed 25,600,000 recordings\n",
            "Processed 25,700,000 recordings\n",
            "Processed 25,800,000 recordings\n",
            "Processed 25,900,000 recordings\n",
            "Processed 26,000,000 recordings\n",
            "Processed 26,100,000 recordings\n",
            "Processed 26,200,000 recordings\n",
            "Processed 26,300,000 recordings\n",
            "Processed 26,400,000 recordings\n",
            "Processed 26,500,000 recordings\n",
            "Processed 26,600,000 recordings\n",
            "Processed 26,700,000 recordings\n",
            "Processed 26,800,000 recordings\n",
            "Processed 26,900,000 recordings\n",
            "Processed 27,000,000 recordings\n",
            "\n",
            "Verifying mapping file:\n",
            "First 5 mappings:\n",
            "Recording: 00b1a29d-ad9e-4b64-aed6-281f69f628ae -> Artist: 89ad4ac3-39f7-470e-963a-56509c546377 (Various Artists)\n",
            "Recording: 0aeea6af-3f85-45f3-88ed-8ce2bdedc4c6 -> Artist: 89ad4ac3-39f7-470e-963a-56509c546377 (Various Artists)\n",
            "Recording: 24f32cf2-127e-45ca-ad19-91ed3ec87409 -> Artist: 89ad4ac3-39f7-470e-963a-56509c546377 (Various Artists)\n",
            "Recording: 28e2548b-9c6f-47b7-8ab5-b1735499f291 -> Artist: 89ad4ac3-39f7-470e-963a-56509c546377 (Various Artists)\n",
            "Recording: 390a9ab5-89c6-4e25-8ebf-f16a39c8c9cb -> Artist: 89ad4ac3-39f7-470e-963a-56509c546377 (Various Artists)\n"
          ]
        }
      ],
      "source": [
        "# Process the recording to artist mapping\n",
        "recording_artist_file = process_recording_to_artist_mapping()\n",
        "\n",
        "# Verify the output\n",
        "print(\"\\nVerifying mapping file:\")\n",
        "with open(recording_artist_file, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)  # Skip header\n",
        "    \n",
        "    print(\"First 5 mappings:\")\n",
        "    for _ in range(5):\n",
        "        row = next(reader)\n",
        "        print(f\"Recording: {row[0]} -> Artist: {row[1]} ({row[2]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final data creation\n",
        "- Create a final data file that contains:\n",
        "    - user_id\n",
        "    - artist_id\n",
        "    - artist_name\n",
        "    - play count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_artist_name_mapping():\n",
        "    \"\"\"Create a mapping of artist IDs to names\"\"\"\n",
        "    artist_names = {}\n",
        "    artist_file = Path(data_root) / \"musicbrainz_artist.csv\"\n",
        "    \n",
        "    with open(artist_file, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # Skip header\n",
        "        \n",
        "        for row in reader:\n",
        "            if len(row) >= 2:\n",
        "                artist_id = row[0]\n",
        "                artist_name = row[1]\n",
        "                artist_names[artist_id] = artist_name\n",
        "    \n",
        "    return artist_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 2,531,408 artist names\n"
          ]
        }
      ],
      "source": [
        "# Create artist name mapping\n",
        "artist_names = create_artist_name_mapping()\n",
        "print(f\"\\nLoaded {len(artist_names):,} artist names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_user_artist_counts():\n",
        "    \"\"\"Create a dictionary of {(user_id, artist_id): play_count}\"\"\"\n",
        "    user_artist_plays = defaultdict(int)\n",
        "    processed = 0\n",
        "    skipped = 0\n",
        "    \n",
        "    # First, load recording to artist mapping into memory\n",
        "    recording_to_artist = {}\n",
        "    with open(Path(scratch_root) / \"recording_artist_mapping.csv\", 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # Skip header\n",
        "        for row in reader:\n",
        "            if len(row) >= 2:  # Ensure we have recording_mbid and artist_mbid\n",
        "                recording_to_artist[row[0]] = row[1]  # Map recording_mbid to artist_mbid\n",
        "    \n",
        "    print(f\"Loaded {len(recording_to_artist):,} recording-artist mappings\")\n",
        "    \n",
        "    # Process listen data\n",
        "    with open(Path(working_root) / \"userid-msid.csv\", 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # Skip header\n",
        "        \n",
        "        for row in reader:\n",
        "            if len(row) < 2:\n",
        "                continue\n",
        "                \n",
        "            user_id, msid = row\n",
        "            \n",
        "            # Get canonical recording MBID\n",
        "            mbid = smallmapping.get(msid)\n",
        "            if not mbid:\n",
        "                skipped += 1\n",
        "                continue\n",
        "            \n",
        "            # Get artist ID\n",
        "            artist_id = recording_to_artist.get(mbid)\n",
        "            if artist_id:\n",
        "                user_artist_plays[(user_id, artist_id)] += 1\n",
        "            \n",
        "            processed += 1\n",
        "            if processed % 100000 == 0:\n",
        "                print(f\"Processed {processed:,} listens\")\n",
        "    \n",
        "    return user_artist_plays, processed, skipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_play_counts(user_artist_plays, artist_names):\n",
        "    \"\"\"\n",
        "    Save user-artist play counts to CSV file\n",
        "    Args:\n",
        "        user_artist_plays: Dictionary of {(user_id, artist_id): play_count}\n",
        "        artist_names: Dictionary of artist_id to artist_name mappings\n",
        "    Returns:\n",
        "        Path to output file\n",
        "    \"\"\"\n",
        "    output_file = Path(working_root) / \"user_artist_playcounts.csv\"\n",
        "    saved_count = 0\n",
        "    \n",
        "    try:\n",
        "        with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['user_id', 'artist_id', 'artist_name', 'play_count'])\n",
        "            \n",
        "            for (user_id, artist_id), count in user_artist_plays.items():\n",
        "                artist_name = artist_names.get(artist_id, \"Unknown\")\n",
        "                writer.writerow([user_id, artist_id, artist_name, count])\n",
        "                saved_count += 1\n",
        "                \n",
        "                if saved_count % 100000 == 0:\n",
        "                    print(f\"Saved {saved_count:,} play counts\")\n",
        "        \n",
        "        print(f\"\\nSuccessfully saved {saved_count:,} play counts to {output_file}\")\n",
        "        return output_file\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error saving play counts: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create user-artist play counts\n",
        "print(\"Creating user-artist play counts...\")\n",
        "user_artist_plays, processed, skipped = create_user_artist_counts()\n",
        "\n",
        "print(f\"\\nProcessing complete:\")\n",
        "print(f\"Processed: {processed:,} listens\")\n",
        "print(f\"Skipped: {skipped:,} listens\")\n",
        "print(f\"Unique user-artist pairs: {len(user_artist_plays):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 100,000 play counts\n",
            "Saved 200,000 play counts\n",
            "Saved 300,000 play counts\n",
            "Saved 400,000 play counts\n",
            "Saved 500,000 play counts\n",
            "Saved 600,000 play counts\n",
            "Saved 700,000 play counts\n",
            "Saved 800,000 play counts\n",
            "Saved 900,000 play counts\n",
            "Saved 1,000,000 play counts\n",
            "Saved 1,100,000 play counts\n",
            "Saved 1,200,000 play counts\n",
            "Saved 1,300,000 play counts\n",
            "Saved 1,400,000 play counts\n",
            "Saved 1,500,000 play counts\n",
            "Saved 1,600,000 play counts\n",
            "Saved 1,700,000 play counts\n",
            "Saved 1,800,000 play counts\n",
            "Saved 1,900,000 play counts\n",
            "Saved 2,000,000 play counts\n",
            "Saved 2,100,000 play counts\n",
            "Saved 2,200,000 play counts\n",
            "Saved 2,300,000 play counts\n",
            "Saved 2,400,000 play counts\n",
            "Saved 2,500,000 play counts\n",
            "Saved 2,600,000 play counts\n",
            "Saved 2,700,000 play counts\n",
            "Saved 2,800,000 play counts\n",
            "Saved 2,900,000 play counts\n",
            "Saved 3,000,000 play counts\n",
            "Saved 3,100,000 play counts\n",
            "Saved 3,200,000 play counts\n",
            "Saved 3,300,000 play counts\n",
            "Saved 3,400,000 play counts\n",
            "Saved 3,500,000 play counts\n",
            "Saved 3,600,000 play counts\n",
            "Saved 3,700,000 play counts\n",
            "Saved 3,800,000 play counts\n",
            "Saved 3,900,000 play counts\n",
            "Saved 4,000,000 play counts\n",
            "Saved 4,100,000 play counts\n",
            "Saved 4,200,000 play counts\n",
            "Saved 4,300,000 play counts\n",
            "Saved 4,400,000 play counts\n",
            "Saved 4,500,000 play counts\n",
            "Saved 4,600,000 play counts\n",
            "Saved 4,700,000 play counts\n",
            "Saved 4,800,000 play counts\n",
            "Saved 4,900,000 play counts\n",
            "Saved 5,000,000 play counts\n",
            "Saved 5,100,000 play counts\n",
            "Saved 5,200,000 play counts\n",
            "Saved 5,300,000 play counts\n",
            "Saved 5,400,000 play counts\n",
            "Saved 5,500,000 play counts\n",
            "Saved 5,600,000 play counts\n",
            "Saved 5,700,000 play counts\n",
            "Saved 5,800,000 play counts\n",
            "Saved 5,900,000 play counts\n",
            "Saved 6,000,000 play counts\n",
            "Saved 6,100,000 play counts\n",
            "Saved 6,200,000 play counts\n",
            "Saved 6,300,000 play counts\n",
            "Saved 6,400,000 play counts\n",
            "Saved 6,500,000 play counts\n",
            "Saved 6,600,000 play counts\n",
            "Saved 6,700,000 play counts\n",
            "Saved 6,800,000 play counts\n",
            "Saved 6,900,000 play counts\n",
            "Saved 7,000,000 play counts\n",
            "Saved 7,100,000 play counts\n",
            "Saved 7,200,000 play counts\n",
            "Saved 7,300,000 play counts\n",
            "Saved 7,400,000 play counts\n",
            "Saved 7,500,000 play counts\n",
            "Saved 7,600,000 play counts\n",
            "Saved 7,700,000 play counts\n",
            "Saved 7,800,000 play counts\n",
            "Saved 7,900,000 play counts\n",
            "\n",
            "Successfully saved 7,947,518 play counts to F:\\SMC\\AMP Lab\\Assignment_02\\amplab-working\\user_artist_playcounts.csv\n",
            "\n",
            "Verifying saved data:\n",
            "user_id,artist_id,artist_name,play_count\n",
            "24076,29266b3d-b5ae-4d09-b721-326246adf68f,In This Moment,75\n",
            "22845,744b52c8-509b-4451-abfd-a17d18d4bd1d,Vince Guaraldi Trio,11\n",
            "2966,b7539c32-53e7-4908-bda3-81449c367da6,Lana Del Rey,143\n",
            "31175,875203e1-8e58-4b86-8dcb-7190faf411c5,J. Cole,43\n",
            "4942,84825fb6-c98c-4b43-a184-c7f70619f355,Roosevelt,144\n"
          ]
        }
      ],
      "source": [
        "# Save the play counts\n",
        "if output_file := save_play_counts(user_artist_plays, artist_names):\n",
        "    # Verify the output\n",
        "    print(\"\\nVerifying saved data:\")\n",
        "    with open(output_file, 'r', encoding='utf-8') as f:\n",
        "        for _ in range(6):  # Header + 5 rows\n",
        "            print(f.readline().strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Structure:\n",
            "   user_id                             artist_id          artist_name  \\\n",
            "0    24076  29266b3d-b5ae-4d09-b721-326246adf68f       In This Moment   \n",
            "1    22845  744b52c8-509b-4451-abfd-a17d18d4bd1d  Vince Guaraldi Trio   \n",
            "2     2966  b7539c32-53e7-4908-bda3-81449c367da6         Lana Del Rey   \n",
            "3    31175  875203e1-8e58-4b86-8dcb-7190faf411c5              J. Cole   \n",
            "4     4942  84825fb6-c98c-4b43-a184-c7f70619f355            Roosevelt   \n",
            "\n",
            "   play_count  \n",
            "0          75  \n",
            "1          11  \n",
            "2         143  \n",
            "3          43  \n",
            "4         144  \n",
            "\n",
            "Total Entries: 7,947,518\n"
          ]
        }
      ],
      "source": [
        "# Check contents of user-artist playcounts file\n",
        "df = pd.read_csv(Path(working_root) / \"user_artist_playcounts.csv\")\n",
        "print(\"Data Structure:\")\n",
        "print(df.head())\n",
        "print(f\"\\nTotal Entries: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Preparing data according to listenbrainz model requirements**\n",
        "\n",
        "Since the model only expects user ID, artist and plays. The dataset structure is modified accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data_for_model():\n",
        "    \n",
        "    input_file = Path(working_root) / \"user_artist_playcounts.csv\"\n",
        "    output_file = Path(working_root) / \"userid-artist-counts.csv\"\n",
        "    \n",
        "    # Create simplified version with only required columns\n",
        "    with open(input_file, 'r', encoding='utf-8') as f_in, \\\n",
        "         open(output_file, 'w', newline='', encoding='utf-8') as f_out:\n",
        "        reader = csv.reader(f_in)\n",
        "        writer = csv.writer(f_out)\n",
        "        \n",
        "        # Skip original header\n",
        "        next(reader)\n",
        "        \n",
        "        # Write header\n",
        "        writer.writerow(['user', 'artist', 'plays'])\n",
        "        \n",
        "        # Process rows - keep only user_id, artist_id, and play_count\n",
        "        for row in reader:\n",
        "            writer.writerow([row[0], row[1], row[3]])\n",
        "    \n",
        "    # Verify\n",
        "    df = pd.read_csv(output_file)\n",
        "    print(\"New data structure:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\nTotal rows: {len(df):,}\")\n",
        "\n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New data structure:\n",
            "    user                                artist  plays\n",
            "0  24076  29266b3d-b5ae-4d09-b721-326246adf68f     75\n",
            "1  22845  744b52c8-509b-4451-abfd-a17d18d4bd1d     11\n",
            "2   2966  b7539c32-53e7-4908-bda3-81449c367da6    143\n",
            "3  31175  875203e1-8e58-4b86-8dcb-7190faf411c5     43\n",
            "4   4942  84825fb6-c98c-4b43-a184-c7f70619f355    144\n",
            "\n",
            "Total rows: 7,947,518\n"
          ]
        }
      ],
      "source": [
        "# Create model-compatible data file\n",
        "model_input_file = prepare_data_for_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKL5JeX3DAdI"
      },
      "source": [
        "# Part 2: Collaborative filtering model\n",
        "\n",
        "This part of the assignment is based on the [implicit tutorial](https://benfred.github.io/implicit/tutorial_lastfm.html) and builds a collaborative filtering model. We reuse as much code as possible from this library.\n",
        "\n",
        "We can find this source code on the [project's github page](https://github.com/benfred/implicit), specifically https://github.com/benfred/implicit/blob/main/implicit/datasets/lastfm.py has code which builds the model based on the last.fm dataset.\n",
        "\n",
        "We've extracted the relevant code from this file and modified it for this task. It's in `listenbrainz_model.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQK1rguHOh-m"
      },
      "source": [
        "## Step 6: Generate matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7NXwD-wXsyfy"
      },
      "outputs": [],
      "source": [
        "# Add data_root to the python path so that we can load the provided file.\n",
        "data_root_path = \"amplab-working\"\n",
        "# You might want to move this file somewhere else and edit it, update the path as necessary\n",
        "import sys\n",
        "sys.path.append(data_root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wj3KofVWs1pW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import listenbrainz_model as lb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "32Sa0EqKs6A3"
      },
      "outputs": [],
      "source": [
        "matrix_artists, matrix_users, plays = lb.load_data_matrix(os.path.join(working_root, \"userid-artist-counts.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RVVZaFOfxI"
      },
      "source": [
        "## Step 7: Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "4c1d52f4fa8b4413af45549f3aacb734",
            "5c26f234183549b59f50385240b3e872",
            "59b8d02620eb42ad9e66c169d451ec57",
            "a1eca46ba5f84a7fb7ebd6b355acb97b",
            "9ff29a7a30fe4d669e0c079f23401fbe",
            "205210dc00db483a8c497aad2bce4d87",
            "57edfa8f92ae415e8e5ad65685390ef1",
            "989aef6804bf496ab74b2abc39a81a03",
            "258eb778a7ca4c4782740a6a8cd8fce7",
            "9d7147276be04bc8889f005d37e5f43d",
            "80642bad0d7a40c7b73fb065fb0ff597"
          ]
        },
        "id": "d2vRg3hks71R",
        "outputId": "fe9869e8-84cf-4fc6-fdfa-f521ecdbdbfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\madha\\anaconda3\\envs\\mirenv\\lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 24 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
            "  check_blas_config()\n",
            "100%|| 15/15 [00:25<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "model = lb.build_model(plays)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwjMdI20PQ7o"
      },
      "source": [
        "We used Artist MBIDs in our data file in order to be unique, so we need one final mapping which allows us to go from an artist MBID to a name.\n",
        "\n",
        "# Artist similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JJMW-u9PPh-G"
      },
      "outputs": [],
      "source": [
        "artist_map = lb.get_artist_map(os.path.join(data_root, \"musicbrainz_artist.csv\"))\n",
        "def format_artist(artist_id):\n",
        "    return f\"\"\"<a href=\"https://musicbrainz.org/artist/{artist_id}\">{artist_map.get(artist_id, \"unknown\")}</a> ({artist_id})\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Recommending similar artists**\n",
        "\n",
        "Finding and recommending similar tracks based on a particular artist index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vcueuItGtCPM"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "def find_similar_artists(artist_mbid: str, N: int = 10) -> HTML:\n",
        "    # Get artist name from mapping\n",
        "    artist_name = artist_map.get(artist_mbid, \"Unknown Artist\")\n",
        "    \n",
        "    # Get similar artists\n",
        "    artist_idx = lb.artist_index(matrix_artists, artist_mbid)\n",
        "    ids, scores = model.similar_items(artist_idx, N=N)\n",
        "    \n",
        "    similar_artists = pd.DataFrame({\n",
        "        \"Artist\": [format_artist(a) for a in matrix_artists[ids]],\n",
        "        \"Similarity Score\": scores.round(3)\n",
        "    })\n",
        "    \n",
        "    # HTML output\n",
        "    content_output = f\"\"\"\n",
        "    <h3>Similar artists to {artist_name}</h3>\n",
        "    <p><small>MBID: {artist_mbid}</small></p>\n",
        "    {similar_artists.to_html(escape=False, index=False)}\n",
        "    \"\"\"\n",
        "    \n",
        "    return HTML(content_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ct7XseQhyIdd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <h3>Similar artists to A. R. Rahman</h3>\n",
              "    <p><small>MBID: e0bba708-bdd3-478d-84ea-c706413bedab</small></p>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Artist</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/e0bba708-bdd3-478d-84ea-c706413bedab\">A. R. Rahman</a> (e0bba708-bdd3-478d-84ea-c706413bedab)</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/aeb71bd8-447d-4415-8ea1-2b7d664f67e1\">Lata Mangeshkar</a> (aeb71bd8-447d-4415-8ea1-2b7d664f67e1)</td>\n",
              "      <td>0.850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/79c5547a-e098-495c-8dac-7e99546aa46b\">Asha Bhosle</a> (79c5547a-e098-495c-8dac-7e99546aa46b)</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/014431e3-c5a3-4a57-b86b-fe8f2e3253ff\">Rahat Fateh Ali Khan</a> (014431e3-c5a3-4a57-b86b-fe8f2e3253ff)</td>\n",
              "      <td>0.816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/793b8f58-80ab-49b3-b5ae-d94034dab10c\">Kishore Kumar</a> (793b8f58-80ab-49b3-b5ae-d94034dab10c)</td>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/a8740949-50a8-4e71-8133-17d31b7cf69c\">Shreya Ghoshal</a> (a8740949-50a8-4e71-8133-17d31b7cf69c)</td>\n",
              "      <td>0.805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/ed3f4831-e3e0-4dc0-9381-f5649e9df221\">Arijit Singh</a> (ed3f4831-e3e0-4dc0-9381-f5649e9df221)</td>\n",
              "      <td>0.805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/2c26fddb-3926-4004-ae27-22a3896a4f26\">Atif Aslam</a> (2c26fddb-3926-4004-ae27-22a3896a4f26)</td>\n",
              "      <td>0.797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/93622908-0806-4173-94c1-9e42597af011\">Sonu Nigam</a> (93622908-0806-4173-94c1-9e42597af011)</td>\n",
              "      <td>0.795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/1dd28f27-4ab3-4a3f-8174-4ccd571a9dce\">Mohit Chauhan</a> (1dd28f27-4ab3-4a3f-8174-4ccd571a9dce)</td>\n",
              "      <td>0.794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/28365249-f3fd-44db-8131-32cb170970c4\">Mohammed Rafi</a> (28365249-f3fd-44db-8131-32cb170970c4)</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/93622908-0806-4173-94c1-9e42597af011,a8740949-50a8-4e71-8133-17d31b7cf69c\">unknown</a> (93622908-0806-4173-94c1-9e42597af011,a8740949-50a8-4e71-8133-17d31b7cf69c)</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/5968383c-11c1-4c5b-ada0-504a38cec8e7\">Nusrat Fateh Ali Khan</a> (5968383c-11c1-4c5b-ada0-504a38cec8e7)</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/d5812475-f8e6-4b5c-951f-7e82720ef041\">Sukhwinder Singh</a> (d5812475-f8e6-4b5c-951f-7e82720ef041)</td>\n",
              "      <td>0.783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/172e980e-ba97-4adb-acb0-d59733c599b6\">KK</a> (172e980e-ba97-4adb-acb0-d59733c599b6)</td>\n",
              "      <td>0.781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find similar artists using artist IDs\n",
        "pinkfloyd_mbid = \"83d91898-7763-47d7-b03b-b92132375c47\"\n",
        "jeremyzucker_mbid = 'e116e0be-c371-4d57-bc09-e2d762d82540'\n",
        "coldplay_mbid = 'cc197bad-dc9c-440d-a5b5-d52ba2e14234'\n",
        "the1975_mbid =  '5b6ebfe0-f72b-4902-bba9-74c8af0f1af0'\n",
        "illenium_mbid = '5f43abf6-92a5-468a-a633-b73f94627972'\n",
        "arrahman_mbid = 'e0bba708-bdd3-478d-84ea-c706413bedab'\n",
        "anirudh_mbid = 'cf76861a-c1f5-456d-8d17-5994d05eecf8'\n",
        "\n",
        "find_similar_artists(arrahman_mbid, N=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making recommendations\n",
        "\n",
        "We can make recommendations using a single user or a batch of users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_user_recommendations(user_id: int, N: int = 15, filter_liked: bool = False) -> HTML:\n",
        "    \n",
        "    # Get recommendations\n",
        "    ids, scores = model.recommend(user_id, plays[user_id], N=N, filter_already_liked_items=filter_liked)\n",
        "    \n",
        "    # recommendations DataFrame\n",
        "    recommendations = pd.DataFrame({\n",
        "        \"Artist\": [format_artist(matrix_artists[i]) for i in ids],\n",
        "        \"Score\": scores.round(3),\n",
        "        \"Already Listened\": np.in1d(ids, plays[user_id].indices)\n",
        "    })\n",
        "    \n",
        "    # HTML output\n",
        "    content_output = f\"\"\"\n",
        "    <h3>Recommendations for User {user_id}</h3>\n",
        "    {recommendations.to_html(escape=False, index=False)}\n",
        "    \"\"\"\n",
        "    \n",
        "    return HTML(content_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <h3>Recommendations for User 12345</h3>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Artist</th>\n",
              "      <th>Score</th>\n",
              "      <th>Already Listened</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/9b58672a-e68e-4972-956e-a8985a165a1f\">Howard Shore</a> (9b58672a-e68e-4972-956e-a8985a165a1f)</td>\n",
              "      <td>1.286</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/53b106e7-0cc6-42cc-ac95-ed8d30a3a98e\">John Williams</a> (53b106e7-0cc6-42cc-ac95-ed8d30a3a98e)</td>\n",
              "      <td>1.230</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/afa80039-cd8a-47ae-947e-538df896586f\">Nicholas Britell</a> (afa80039-cd8a-47ae-947e-538df896586f)</td>\n",
              "      <td>1.220</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/e6de1f3b-6484-491c-88dd-6d619f142abc\">Hans Zimmer</a> (e6de1f3b-6484-491c-88dd-6d619f142abc)</td>\n",
              "      <td>1.206</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/348f3a5f-5112-4d72-b33b-11c60b4f9af2\">Thomas Newman</a> (348f3a5f-5112-4d72-b33b-11c60b4f9af2)</td>\n",
              "      <td>1.190</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/a16e47f5-aa54-47fe-87e4-bb8af91a9fdd\">Ennio Morricone</a> (a16e47f5-aa54-47fe-87e4-bb8af91a9fdd)</td>\n",
              "      <td>1.171</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/b16057eb-b7aa-4306-8f3e-430eec1f5a01\">Ben Prunty</a> (b16057eb-b7aa-4306-8f3e-430eec1f5a01)</td>\n",
              "      <td>1.144</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/78471616-3cb4-4139-a148-aeac3c7d0f79\">Ludwig Gransson</a> (78471616-3cb4-4139-a148-aeac3c7d0f79)</td>\n",
              "      <td>1.138</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/49c4816a-dcbe-4dfa-866a-563a51b76f48\">Daniel Pemberton</a> (49c4816a-dcbe-4dfa-866a-563a51b76f48)</td>\n",
              "      <td>1.137</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/96eca91a-fdb5-4a0e-908b-ba526ba166df\">Gareth Coker</a> (96eca91a-fdb5-4a0e-908b-ba526ba166df)</td>\n",
              "      <td>1.135</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/4033292a-fcd3-4138-8b15-79be991f954e\">fingerspit</a> (4033292a-fcd3-4138-8b15-79be991f954e)</td>\n",
              "      <td>1.131</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/1ee18fb3-18a6-4c7f-8ba0-bc41cdd0462e\">Stevie Wonder</a> (1ee18fb3-18a6-4c7f-8ba0-bc41cdd0462e)</td>\n",
              "      <td>1.128</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/4967c0a1-b9f3-465e-8440-4598fd9fc33c\">Enya</a> (4967c0a1-b9f3-465e-8440-4598fd9fc33c)</td>\n",
              "      <td>1.101</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/aab5c954-cabe-432e-899e-1c4f99757327\">Toto</a> (aab5c954-cabe-432e-899e-1c4f99757327)</td>\n",
              "      <td>1.100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/abc31be8-02b2-4bb1-867d-604d50b7be78\">LImpratrice</a> (abc31be8-02b2-4bb1-867d-604d50b7be78)</td>\n",
              "      <td>1.094</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Recommend artists for a user\n",
        "user_id = 12345\n",
        "get_user_recommendations(user_id, N=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making batch recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_batch_recommendations(batch_size: int = 10, N: int = 5, filter_liked: bool = False) -> HTML:\n",
        "    \n",
        "    # Get first batch_size users\n",
        "    userids = np.arange(batch_size)\n",
        "    \n",
        "    # Get batch recommendations\n",
        "    ids, scores = model.recommend(userids, plays[userids], N=N, filter_already_liked_items=filter_liked)\n",
        "    \n",
        "    all_recommendations = []\n",
        "    \n",
        "    for user_idx, (user_artists, user_scores) in enumerate(zip(ids, scores)):\n",
        "        # Create user recommendations\n",
        "        user_recs = pd.DataFrame({\n",
        "            \"User ID\": userids[user_idx],\n",
        "            \"Artist\": [format_artist(matrix_artists[i]) for i in user_artists],\n",
        "            \"Score\": user_scores.round(3),\n",
        "            \"Already Listened\": np.in1d(user_artists, plays[userids[user_idx]].indices)\n",
        "        })\n",
        "        all_recommendations.append(user_recs)\n",
        "    \n",
        "    # Combine all recommendations\n",
        "    combined_df = pd.concat(all_recommendations)\n",
        "    \n",
        "    # Create HTML output\n",
        "    content_output = f\"\"\"\n",
        "    <h3>Batch Recommendations for {batch_size} Users</h3>\n",
        "    <p><small>Top {N} recommendations per user</small></p>\n",
        "    {combined_df.to_html(escape=False, index=False)}\n",
        "    \"\"\"\n",
        "    \n",
        "    return HTML(content_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <h3>Batch Recommendations for 5 Users</h3>\n",
              "    <p><small>Top 5 recommendations per user</small></p>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>User ID</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Score</th>\n",
              "      <th>Already Listened</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/a505bb48-ad65-4af4-ae47-29149715bff9\">Thievery Corporation</a> (a505bb48-ad65-4af4-ae47-29149715bff9)</td>\n",
              "      <td>1.286</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/4e7473b1-0e6e-4530-b374-b9c80ec7832b\">Kid Francescoli</a> (4e7473b1-0e6e-4530-b374-b9c80ec7832b)</td>\n",
              "      <td>1.286</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/ccda046a-2674-4f7d-97e6-f23d6c156432\">Dead Can Dance</a> (ccda046a-2674-4f7d-97e6-f23d6c156432)</td>\n",
              "      <td>1.269</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/86e2e2ad-6d1b-44fd-9463-b6683718a1cc\">JeanMichel Jarre</a> (86e2e2ad-6d1b-44fd-9463-b6683718a1cc)</td>\n",
              "      <td>1.266</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/e095407c-4103-4c66-b616-0dab1db05106\">Thylacine</a> (e095407c-4103-4c66-b616-0dab1db05106)</td>\n",
              "      <td>1.240</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/20244d07-534f-4eff-b4d4-930878889970\">Taylor Swift</a> (20244d07-534f-4eff-b4d4-930878889970)</td>\n",
              "      <td>0.800</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/1882fe91-cdd9-49c9-9956-8e06a3810bd4\">Sabrina Carpenter</a> (1882fe91-cdd9-49c9-9956-8e06a3810bd4)</td>\n",
              "      <td>0.759</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/6925db17-f35e-42f3-a4eb-84ee6bf5d4b0\">Olivia Rodrigo</a> (6925db17-f35e-42f3-a4eb-84ee6bf5d4b0)</td>\n",
              "      <td>0.748</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/56a55378-f155-48de-80a5-d80104221267\">Chappell Roan</a> (56a55378-f155-48de-80a5-d80104221267)</td>\n",
              "      <td>0.739</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/3c25958a-2bff-4381-8eb4-7dbe84c3e75e\">Sort Stue</a> (3c25958a-2bff-4381-8eb4-7dbe84c3e75e)</td>\n",
              "      <td>0.719</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/9567a29f-cb0e-4880-8b23-beac15a2cf94\">Eelke Kleijn</a> (9567a29f-cb0e-4880-8b23-beac15a2cf94)</td>\n",
              "      <td>1.249</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/67db280d-c3e4-49d9-978e-4050f4e209ef\">Amelie Lens</a> (67db280d-c3e4-49d9-978e-4050f4e209ef)</td>\n",
              "      <td>1.236</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/9aec0d9a-c5b3-45ab-839c-d60f18534437\">Mesh</a> (9aec0d9a-c5b3-45ab-839c-d60f18534437)</td>\n",
              "      <td>1.227</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/272deaa4-4699-46ee-abe8-c63f495142d7\">Worakls</a> (272deaa4-4699-46ee-abe8-c63f495142d7)</td>\n",
              "      <td>1.225</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/477b8c0c-c5fc-4ad2-b5b2-191f0bf2a9df,f1348139-efb5-43c7-9204-199827efad3c\">unknown</a> (477b8c0c-c5fc-4ad2-b5b2-191f0bf2a9df,f1348139-efb5-43c7-9204-199827efad3c)</td>\n",
              "      <td>1.202</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/00467da8-2a92-498f-8b10-a80889bcded7\">The Horrors</a> (00467da8-2a92-498f-8b10-a80889bcded7)</td>\n",
              "      <td>1.145</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/09d8290b-6ada-422f-8ce3-19349fb1c15d\">Sleaford Mods</a> (09d8290b-6ada-422f-8ce3-19349fb1c15d)</td>\n",
              "      <td>1.115</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/8a74e5ea-6f68-49e1-951c-80d2291f7c3f\">Dry Cleaning</a> (8a74e5ea-6f68-49e1-951c-80d2291f7c3f)</td>\n",
              "      <td>1.106</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/9d4c4835-c71a-4647-a4fc-263e26832cd0\">Grandaddy</a> (9d4c4835-c71a-4647-a4fc-263e26832cd0)</td>\n",
              "      <td>1.090</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/c69af97b-4d3b-4f72-9746-829b6b9d5f88\">Yard Act</a> (c69af97b-4d3b-4f72-9746-829b6b9d5f88)</td>\n",
              "      <td>1.074</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/8538e728-ca0b-4321-b7e5-cff6565dd4c0\">Depeche Mode</a> (8538e728-ca0b-4321-b7e5-cff6565dd4c0)</td>\n",
              "      <td>1.069</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/f9ef7a22-4262-4596-a2a8-1d19345b8e50\">Garbage</a> (f9ef7a22-4262-4596-a2a8-1d19345b8e50)</td>\n",
              "      <td>1.068</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/5b11f4ce-a62d-471e-81fc-a69a8278c7da\">Nirvana</a> (5b11f4ce-a62d-471e-81fc-a69a8278c7da)</td>\n",
              "      <td>1.054</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/5441c29d-3602-4898-b1a1-b77fa23b8e50\">David Bowie</a> (5441c29d-3602-4898-b1a1-b77fa23b8e50)</td>\n",
              "      <td>1.044</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td><a href=\"https://musicbrainz.org/artist/83d91898-7763-47d7-b03b-b92132375c47\">Pink Floyd</a> (83d91898-7763-47d7-b03b-b92132375c47)</td>\n",
              "      <td>1.032</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_batch_recommendations(batch_size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\n",
        "\n",
        "**Most common artists from our musicbrainz data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# analyzing the most common artsits in our dataset\n",
        "\n",
        "def analyze_common_artists(n=10):\n",
        "    \"\"\"Analyze most common artists in the dataset\"\"\"\n",
        "    df = pd.read_csv(Path(working_root) / \"user_artist_playcounts.csv\")\n",
        "    \n",
        "    # Group by artist and sum play counts\n",
        "    top_artists = df.groupby(['artist_id', 'artist_name'])['play_count'].sum()\\\n",
        "                   .sort_values(ascending=False)\\\n",
        "                   .head(n)\n",
        "    \n",
        "    # Create formatted output\n",
        "    results = pd.DataFrame(top_artists).reset_index()\n",
        "    results.columns = ['Artist MBID', 'Artist Name', 'Total Plays']\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist MBID</th>\n",
              "      <th>Artist Name</th>\n",
              "      <th>Total Plays</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20244d07-534f-4eff-b4d4-930878889970</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>468544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>260b6184-8828-48eb-945c-bc4cb6fc34ca</td>\n",
              "      <td>Charli xcx</td>\n",
              "      <td>287828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f59c5520-5f46-4d2c-b2c4-822eabf53419</td>\n",
              "      <td>Linkin Park</td>\n",
              "      <td>280998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
              "      <td>Radiohead</td>\n",
              "      <td>231478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>381086ea-f511-4aba-bdf9-71c753dc5077</td>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>174880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387</td>\n",
              "      <td>Ariana Grande</td>\n",
              "      <td>170672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>f4abc0b5-3f7a-4eff-8f78-ac078dbce533</td>\n",
              "      <td>Billie Eilish</td>\n",
              "      <td>160655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
              "      <td>The Beatles</td>\n",
              "      <td>142774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>b51c672b-85e0-48fe-8648-470a2422229f</td>\n",
              "      <td>aespa</td>\n",
              "      <td>140071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>164f0d73-1234-4e2c-8743-d77bf2191051</td>\n",
              "      <td>Ye</td>\n",
              "      <td>131596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Artist MBID     Artist Name  Total Plays\n",
              "0  20244d07-534f-4eff-b4d4-930878889970    Taylor Swift       468544\n",
              "1  260b6184-8828-48eb-945c-bc4cb6fc34ca      Charli xcx       287828\n",
              "2  f59c5520-5f46-4d2c-b2c4-822eabf53419     Linkin Park       280998\n",
              "3  a74b1b7f-71a5-4011-9441-d0b5e4122711       Radiohead       231478\n",
              "4  381086ea-f511-4aba-bdf9-71c753dc5077  Kendrick Lamar       174880\n",
              "5  f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387   Ariana Grande       170672\n",
              "6  f4abc0b5-3f7a-4eff-8f78-ac078dbce533   Billie Eilish       160655\n",
              "7  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d     The Beatles       142774\n",
              "8  b51c672b-85e0-48fe-8648-470a2422229f           aespa       140071\n",
              "9  164f0d73-1234-4e2c-8743-d77bf2191051              Ye       131596"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display top artists\n",
        "top_artists = analyze_common_artists()\n",
        "display(top_artists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Check Unique users in our data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Statistics:\n",
            "Total entries: 7,947,518\n",
            "Unique users: 15,780\n",
            "Average entries per user: 503.6\n"
          ]
        }
      ],
      "source": [
        "# Check unique users in final dataset\n",
        "df = pd.read_csv(Path(working_root) / \"user_artist_playcounts.csv\")\n",
        "unique_users = df['user_id'].nunique()\n",
        "total_entries = len(df)\n",
        "\n",
        "print(f\"Dataset Statistics:\")\n",
        "print(f\"Total entries: {total_entries:,}\")\n",
        "print(f\"Unique users: {unique_users:,}\")\n",
        "print(f\"Average entries per user: {total_entries/unique_users:.1f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mirenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "205210dc00db483a8c497aad2bce4d87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258eb778a7ca4c4782740a6a8cd8fce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c1d52f4fa8b4413af45549f3aacb734": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c26f234183549b59f50385240b3e872",
              "IPY_MODEL_59b8d02620eb42ad9e66c169d451ec57",
              "IPY_MODEL_a1eca46ba5f84a7fb7ebd6b355acb97b"
            ],
            "layout": "IPY_MODEL_9ff29a7a30fe4d669e0c079f23401fbe"
          }
        },
        "57edfa8f92ae415e8e5ad65685390ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b8d02620eb42ad9e66c169d451ec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_989aef6804bf496ab74b2abc39a81a03",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_258eb778a7ca4c4782740a6a8cd8fce7",
            "value": 15
          }
        },
        "5c26f234183549b59f50385240b3e872": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205210dc00db483a8c497aad2bce4d87",
            "placeholder": "",
            "style": "IPY_MODEL_57edfa8f92ae415e8e5ad65685390ef1",
            "value": "100%"
          }
        },
        "80642bad0d7a40c7b73fb065fb0ff597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "989aef6804bf496ab74b2abc39a81a03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7147276be04bc8889f005d37e5f43d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff29a7a30fe4d669e0c079f23401fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1eca46ba5f84a7fb7ebd6b355acb97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7147276be04bc8889f005d37e5f43d",
            "placeholder": "",
            "style": "IPY_MODEL_80642bad0d7a40c7b73fb065fb0ff597",
            "value": "15/15[02:32&lt;00:00,10.14s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
